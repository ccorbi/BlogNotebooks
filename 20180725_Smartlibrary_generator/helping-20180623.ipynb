{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-23T20:24:27.879559Z",
     "start_time": "2018-07-23T20:24:26.445232Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import pickle\n",
    "import glob\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-23T20:24:28.694609Z",
     "start_time": "2018-07-23T20:24:27.887939Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-17T18:27:11.714120Z",
     "start_time": "2018-07-17T18:27:11.709407Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fix random state\n",
    "random_state = np.random.RandomState(42)\n",
    "random.seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## One-hot Functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_categories = 3\n",
    "all_categories =  [('H', 'G', 'I' ), \n",
    "                   ('E','B'), \n",
    "                   ('S','T','C','-')]\n",
    "\n",
    "\n",
    "all_letters = ['_','C', 'V', 'T', 'F', 'Y', 'A', 'P', 'W', 'I', 'M', 'L', 'S', 'G', 'H', 'D', 'E', 'N', 'Q', 'R', 'K']\n",
    "n_letters = len(all_letters)\n",
    "\n",
    "\n",
    "\n",
    "# One-hot vector for category\n",
    "def categoryTensor(category):\n",
    "    li = all_categories.index(category)\n",
    "    tensor = torch.zeros(1, n_categories)\n",
    "    tensor[0][li] = 1\n",
    "    return tensor\n",
    "\n",
    "# One-hot matrix of first to last letters (not including EOS) for input\n",
    "def inputTensor(line):\n",
    "    tensor = torch.zeros(len(line), 1, n_letters)\n",
    "    for li in range(len(line)):\n",
    "        letter = line[li]\n",
    "        tensor[li][0][all_letters.index(letter)] = 1\n",
    "    return tensor\n",
    "\n",
    "# LongTensor of second letter to end (EOS) for target\n",
    "def targetTensor(line):\n",
    "    letter_indexes = [all_letters.index(line[li]) for li in range(1, len(line))]\n",
    "    letter_indexes.append( all_letters.index('_' )) # EOS\n",
    "    return torch.LongTensor(letter_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def from_vec2char(tensor):\n",
    "    for k in tensor[0]:\n",
    "        for idx, i in enumerate(k):\n",
    "            if i.data.cpu().numpy() == 1:\n",
    "                return int_to_char[idx]\n",
    "\n",
    "            \n",
    "            \n",
    "def from_code2chars(tensor):\n",
    "    resu = list()\n",
    "    for a in tensor.data.cpu().numpy():\n",
    "        resu.append(int_to_char[a])\n",
    "    return ''.join(resu[:-1])\n",
    "\n",
    "\n",
    "def decode_library(lib):\n",
    "    renature = list()\n",
    "    for item in lib:\n",
    "        f = from_vec2char(item[1])\n",
    "        seq = from_code2chars(item[2])\n",
    "        renature.append(f+seq)\n",
    "    return renature\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-17T18:27:12.132509Z",
     "start_time": "2018-07-17T18:27:12.095184Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Model helper functions, generate\n",
    "\n",
    "\n",
    "\n",
    "def sample_temperature(x, temperature=1.0):\n",
    "    x = x.reshape(-1).astype(np.float)\n",
    "    x /= temperature\n",
    "    x = np.exp(x)\n",
    "    x /= np.sum(x)\n",
    "    x = random_state.multinomial(1, x)\n",
    "    x = np.argmax(x)\n",
    "    return x.astype(np.int64)\n",
    "\n",
    "\n",
    "\n",
    "def sample(category, start_letter='A', temp=.8):\n",
    "    max_length= 9\n",
    "    with torch.no_grad():  # no need to track history in sampling\n",
    "        category_tensor = categoryTensor(category)\n",
    "        input = inputTensor(start_letter)\n",
    "        hidden = rnn.initHidden()\n",
    "\n",
    "        output_name = start_letter\n",
    "\n",
    "        for i in range(max_length):\n",
    "            output, hidden = rnn(category_tensor, input[0], hidden)\n",
    "            #topv, topi = output.topk(1)\n",
    "            #topi = topi[0][0]\n",
    "            o = output.cpu()\n",
    "            topi = sample_temperature(o.data.numpy(), temperature=temp)\n",
    "            #if topi == n_letters - 1:\n",
    "            #    break\n",
    "            #else:\n",
    "            letter = all_letters[topi]\n",
    "            output_name += letter\n",
    "            input = inputTensor(letter)\n",
    "\n",
    "        return output_name\n",
    "\n",
    "\n",
    "def library_generation( name,n=100, kind='H', t=.65):\n",
    "    \n",
    "    labels = {'H':('H', 'G', 'I' ),\n",
    "             'E': ('E','B'),\n",
    "             'C':('S','T','C','-')}\n",
    "    firsttest = list()\n",
    "    for i in range(n):\n",
    "        a = random.choice(all_letters)\n",
    "        seq = sample(  labels[kind], a, temp=t)\n",
    "        if not '_' in seq:\n",
    "            firsttest.append(seq)\n",
    "\n",
    "    for i in firsttest:\n",
    "        o = open('{}_{}_{}_t{}.fasta'.format(name,kind,i,t),'w')\n",
    "        print('>'+i, file=o)\n",
    "        print(i, file=o)\n",
    "\n",
    "        o.close()\n",
    "\n",
    "        \n",
    "def fillthegaps(kind, motifs='AXPXXXPXXXK', temp=.65):\n",
    "    max_length= 9\n",
    "    \n",
    "    labels = {'H':('H', 'G', 'I' ),\n",
    "             'E': ('E','B'),\n",
    "             'C':('S','T','C','-')}\n",
    "    \n",
    "    with torch.no_grad():  # no need to track history in sampling\n",
    "        category_tensor = categoryTensor(labels[kind])\n",
    "        \n",
    "        hidden = rnn.initHidden()\n",
    "        try:\n",
    "            input = inputTensor(motifs[0])\n",
    "        except:\n",
    "            aa = random.choice(['C', 'V', 'T', 'F', 'Y', 'A', 'P', 'W', 'I', 'M', 'L', 'S', 'G', 'H', 'D', 'E', 'N', 'Q', 'R', 'K'])\n",
    "            input = inputTensor(aa)\n",
    "        output_name = list()\n",
    "        \n",
    "        hidden = rnn.initHidden()\n",
    "        for i in range(len(motifs)):\n",
    "            \n",
    "            if motifs[i] != 'X':\n",
    "                # reset hidden layer every time? ///// probably I need a context layer\n",
    "                output_name.append(motifs[i])\n",
    "                input = inputTensor(motifs[i])\n",
    "                \n",
    "            \n",
    "            if motifs[i] == 'X':\n",
    "            \n",
    "                output, hidden = rnn(category_tensor, input[0], hidden)\n",
    "                #topv, topi = output.topk(1)\n",
    "                #topi = topi[0][0]\n",
    "                o = output.cpu()\n",
    "                topi = sample_temperature(o.data.numpy(), temperature=temp)\n",
    "                #if topi == n_letters - 1:\n",
    "                #    break\n",
    "                #else:\n",
    "\n",
    "                letter = all_letters[topi]\n",
    "                output_name.append( letter)\n",
    "                input = inputTensor(letter)\n",
    "\n",
    "        return ''.join(output_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plotting & Analysis\n",
    "\n",
    "def get_avgcontent(path):\n",
    "    results = dict()\n",
    "    folders = glob.glob(path)\n",
    "    data = {'C':list(),\n",
    "            'H': list(),\n",
    "            'E': list()}\n",
    "    \n",
    "    for f in folders:\n",
    "        out = glob.glob(f+'/*.ss2')\n",
    "        if len(out) > 0:\n",
    "            dat = pd.read_csv(out[0], skip_blank_lines=True, skiprows=1, names=['idx','res','SS','Prob_C','Prob_H','Prob_E'], delim_whitespace=True)\n",
    "            for struct, garbage_bin in data.items():\n",
    "                garbage_bin.append(dat[dat['SS']==struct].shape[0]/10)\n",
    "        #s = dat[dat['SS']==]\n",
    "        \n",
    "    for struct, garbage_bin in data.items():\n",
    "        #t = 0\n",
    "        #garbage_bin:\n",
    "        #    if i > 4:\n",
    "                #print(i)\n",
    "                #t +=1\n",
    "        results[struct] = garbage_bin\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-23T20:27:03.728732Z",
     "start_time": "2018-07-23T20:27:03.723074Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-23T20:29:21.907601Z",
     "start_time": "2018-07-23T20:29:21.892097Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_psipred(seq):\n",
    "        o = open('{}.fasta'.format(seq),'w')\n",
    "        print('>'+seq, file=o)\n",
    "        print(seq, file=o)\n",
    "\n",
    "        o.close()\n",
    "        \n",
    "        p = subprocess.Popen(['run_psipred.pl', \n",
    "                              seq+'.fasta', \n",
    "                              '-d',\n",
    "                              '/Users/ccorbi/Desktop/DEMO_insights/uniprot_sprot.fasta', '-o', seq])\n",
    "        p.wait()\n",
    "        \n",
    "        dat = pd.read_csv('./{0}/{0}.fasta.ss2'.format(seq), skip_blank_lines=True, skiprows=1, names=['idx','res','SS','Prob_C','Prob_H','Prob_E'], delim_whitespace=True)\n",
    "        pred = ''.join(dat['SS'].get_values())\n",
    "        return pred\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
